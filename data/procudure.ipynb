{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## procedure embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from openai import OpenAI\n",
    "# import json\n",
    "\n",
    "# def get_vectors(data):\n",
    "#     client = OpenAI(\n",
    "#     api_key='',  \n",
    "#     base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\" \n",
    "#     )\n",
    "#     completion = client.embeddings.create(\n",
    "#     model=\"text-embedding-v3\",\n",
    "#     input=data,\n",
    "#     dimensions=1024,\n",
    "#     encoding_format=\"float\"\n",
    "#     )\n",
    "#     resp = completion.model_dump_json() \n",
    "#     dic = json.loads(resp)\n",
    "#     embeddings = [x['embedding'] for x in dic['data']]\n",
    "#     return embeddings\n",
    "\n",
    "\n",
    "# with open(\"./procedure/procedure.json\", \"r\", encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# titles = [x['title'] for x in data]\n",
    "\n",
    "# embeddings = get_vectors(titles[0:10]) \n",
    "# embeddings = embeddings + get_vectors(titles[10:])\n",
    "# assert len(embeddings) == len(data)\n",
    "# for (i, x) in enumerate(data):\n",
    "#     x['embedding'] = embeddings[i]\n",
    "\n",
    "# with open(\"./procedure/procedure.json\", \"w\", encoding='utf-8') as f:\n",
    "#     json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('./procedure/procedure.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    if item.get('img'):\n",
    "        # 将 ./procedure/item.get('img').png 重命名为 i.png\n",
    "         os.rename(f'./procedure/{item.get(\"img\")}', f'./procedure/{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n",
      "page_content='成绩单、学籍证明打印办理流程' metadata={'idx': 12}\n",
      "根据提供的上下文，打印成绩单的方法如下：\n",
      "\n",
      "1. **在校生**：\n",
      "   - 可以在自助打印机上打印成绩单。\n",
      "   - 也可以到本科生院学籍科（明远楼203室）凭有效身份证件办理。\n",
      "\n",
      "2. **毕业生**：\n",
      "   - 可以联系云南大学档案馆（0871-65031310）查询成绩单。\n",
      "   - 如需在成绩单上加盖本科生院成绩专用章，可以将成绩单邮寄至云南大学本科生院学籍科（呈贡校区明远楼203室），并留下回寄地址，学籍科盖章后以顺丰到付件寄回。\n",
      "   - 2004届（含）及以后的毕业生，还可以将本人身份证（正反面）、毕业证（或结业证）、学位证（如未获得学位可不提供）的扫描件发邮件至1761753176@qq.com，邮件正文注明需要成绩单的份数，并写明邮寄地址及联系方式，学籍科核查无误后打印学生成绩单，加盖本科生院成绩专用章以顺丰到付件寄给学生。\n",
      "\n",
      "3. **注意事项**：\n",
      "   - 本科生院不提供任何形式的电子版成绩单。\n",
      "   - 毕业生（或结业生）已无学籍，不能开具学籍证明。\n",
      "\n",
      "4. **咨询方式**：\n",
      "   - 如有疑问，可拨打本科生院学籍科电话咨询：0871-65032602。\n",
      "\n",
      "请根据你的具体身份（在校生或毕业生）选择相应的方法进行操作。"
     ]
    }
   ],
   "source": [
    "# -*- coding = utf-8 -*-\n",
    "# @Time : 2025/1/4 14:52\n",
    "# @Author : lx\n",
    "# @File : demo2.py\n",
    "# @Software : PyCharm\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# 初始化模型\n",
    "model = ChatOpenAI(\n",
    "    model=\"glm-4-plus\",\n",
    "    openai_api_key=\"\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    streaming=True \n",
    ")\n",
    "\n",
    "os.environ['ZHIPUAI_API_KEY'] = ''\n",
    "\n",
    "# 加载数据\n",
    "with open(\"./procedure/procedure.json\", \"r\", encoding='utf-8') as f:\n",
    "    procedure_data = json.load(f)\n",
    "\n",
    "document = [\n",
    "    Document(\n",
    "        page_content=x['title'],\n",
    "        metadata={\"idx\": idx}\n",
    "    ) for idx, x in enumerate(procedure_data)\n",
    "]\n",
    "\n",
    "# 初始化嵌入模型\n",
    "embedding = ZhipuAIEmbeddings(model='embedding-3')\n",
    "\n",
    "# 检查是否已有存储的向量数据库\n",
    "persist_dir = \"./chroma_db\"\n",
    "if os.path.exists(persist_dir) and os.listdir(persist_dir):\n",
    "    # 从磁盘加载\n",
    "    print(\"Loading existing vector store...\")\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_dir,\n",
    "        embedding_function=embedding\n",
    "    )\n",
    "else:\n",
    "    # 创建新的并存储到磁盘\n",
    "    print(\"Creating new vector store...\")\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=document,\n",
    "        embedding=embedding,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "\n",
    "# 定义检索器\n",
    "retriever = RunnableLambda(vector_store.similarity_search).bind(k=1)\n",
    "\n",
    "# 定义 prompt\n",
    "message = \"\"\"\n",
    "使用提供的上下文进行回答。若无法从上下文中找到答案，请回答“我不知道”。\n",
    "{question}\n",
    "上下文：{content}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([('human', message)])\n",
    "\n",
    "# 定义 chain\n",
    "def format_response(data):\n",
    "    \"\"\"处理检索结果和用户问题\"\"\"\n",
    "    retrieved_docs = data[\"retrieved_docs\"]\n",
    "    question = data[\"question\"]\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return {\"question\": question, \"content\": \"未找到相关信息\"}\n",
    "    \n",
    "    doc = retrieved_docs[0]  # 获取第一个匹配的文档\n",
    "    print(doc)\n",
    "    idx = doc.metadata['idx']  # 获取 metadata 中的 idx\n",
    "    text = procedure_data[idx]['text']  # 从 procedure_data 获取对应的 text\n",
    "    #print(f'question: {question} content: {text}')\n",
    "    return {\"question\": question, \"content\": text}\n",
    "\n",
    "# 构建 chain\n",
    "chain = (\n",
    "    {\"retrieved_docs\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | RunnableLambda(format_response) \n",
    "    | prompt_template \n",
    "    | model\n",
    ")\n",
    "\n",
    "# 测试查询\n",
    "for chunk in chain.stream(\"如何打印成绩单\"):\n",
    "    print(chunk.content, end=\"\", flush=True)  # 逐块打印，不换行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intention dataset generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from itertools import product\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 同义词词典\n",
    "SYNONYMS = {\n",
    "    \"流程\": [\"步骤\", \"手续\", \"程序\", \"过程\"],\n",
    "    \"办理\": [\"申请\", \"处理\", \"操作\", \"进行\"],\n",
    "    \"如何\": [\"怎样\", \"怎么\", \"请问如何\", \"如何操作\"],\n",
    "    \"信息\": [\"资料\", \"详情\", \"详细介绍\", \"基本情况\"],\n",
    "    \"查询\": [\"查找\", \"搜索\", \"了解\", \"获取\"]\n",
    "}\n",
    "\n",
    "# 数据增强函数\n",
    "def augment_text(text):\n",
    "    words = text.split()\n",
    "    # 随机替换同义词\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in SYNONYMS:\n",
    "            words[i] = random.choice(SYNONYMS[words[i]])\n",
    "    # 随机删除词（20%概率）\n",
    "    if len(words) > 3 and random.random() < 0.2:\n",
    "        del words[random.randint(0, len(words)-1)]\n",
    "    # 随机插入词（20%概率）\n",
    "    if random.random() < 0.2:\n",
    "        words.insert(random.randint(0, len(words)), \"的\")\n",
    "    return \"\".join(words)\n",
    "\n",
    "# 扩展后的模板\n",
    "PROCESS_TEMPLATES = [\n",
    "    \"如何办理{}？\", \"{}的流程是什么？\", \"怎样申请{}？\", \"请问{}需要什么步骤？\",\n",
    "    \"{}的办理流程是怎样的？\", \"办理{}的具体步骤有哪些？\", \"我需要了解{}的流程\", \n",
    "    \"申请{}的步骤是怎样的？\", \"关于{}的详细流程\", \"怎么操作{}？\",\n",
    "    \"{}应该怎么办理？\", \"有没有{}的操作指南？\", \"求{}的完整流程说明\"\n",
    "]\n",
    "\n",
    "ENTITY_TEMPLATES = [\n",
    "    \"{}的信息是什么？\", \"查找关于{}的资料\", \"{}的相关信息\", \"查询{}的详细信息\",\n",
    "    \"{}属于哪个学院？\", \"{}的具体位置在哪里？\", \"{}的联系方式是什么？\",\n",
    "    \"如何联系{}？\", \"{}的课程安排是怎样的？\", \"{}的教师有哪些？\",\n",
    "    \"{}的开放时间是？\", \"{}的负责部门是哪个？\", \"关于{}的最新通知\"\n",
    "]\n",
    "\n",
    "# 数据集生成\n",
    "def generate_enhanced_dataset():\n",
    "    # 流程类问题生成（10倍扩展）\n",
    "    procedures = [p.split(\"流程\")[0].strip() for p in open(\"./procedure/procedure_list.txt\").read().splitlines()]\n",
    "    \n",
    "    process_questions = []\n",
    "    for p in procedures:\n",
    "        for t in PROCESS_TEMPLATES:\n",
    "            base_question = t.format(p)\n",
    "            # 生成原始问题\n",
    "            process_questions.append(base_question)\n",
    "            # 生成增强问题（3个变体）\n",
    "            for _ in range(3):\n",
    "                process_questions.append(augment_text(base_question))\n",
    "    \n",
    "    # 实体类问题生成（10倍扩展）\n",
    "    entities = [\n",
    "        (\"文学院历史与档案学院\", \"学院\"),\n",
    "        (\"格物楼1栋1103\", \"教室\"),\n",
    "        (\"C语言程序设计\", \"课程\"),\n",
    "        (\"张学杰\", \"教师\"),\n",
    "        (\"云南大学\", \"学校\"),\n",
    "        (\"文渊楼211\", \"教室\"),\n",
    "        (\"云南大学呈贡校区图书馆\", \"图书馆\"),\n",
    "        (\"外国语学院\", \"学院\"),\n",
    "        (\"法学院\", \"学院\"),\n",
    "        (\"王津\", \"教师\"),\n",
    "        (\"高等数学\", \"课程\"),\n",
    "        (\"信息学院\", \"学院\"),\n",
    "        (\"软件学院\", \"学院\"),\n",
    "        (\"格物楼\", \"教学楼\")\n",
    "    ]\n",
    "    \n",
    "    entity_questions = []\n",
    "    for e, _ in entities:\n",
    "        for t in ENTITY_TEMPLATES:\n",
    "            base_question = t.format(e)\n",
    "            # 生成原始问题\n",
    "            entity_questions.append(base_question)\n",
    "            # 生成增强问题（3个变体）\n",
    "            for _ in range(3):\n",
    "                entity_questions.append(augment_text(base_question))\n",
    "    \n",
    "    # 创建DataFrame（添加负样本）\n",
    "    data = {\n",
    "        \"text\": process_questions + entity_questions,\n",
    "        \"label\": [0]*len(process_questions) + [1]*len(entity_questions)\n",
    "    }\n",
    "    \n",
    "    # 添加5%的负样本\n",
    "    negative_samples = [\n",
    "        \"今天的天气怎么样？\",\n",
    "        \"云南大学的历史有多久？\",\n",
    "        \"校长办公室的电话是多少？\",\n",
    "        \"图书馆今天的开馆时间\",\n",
    "        \"最近的食堂在哪里？\"\n",
    "    ]\n",
    "    data[\"text\"].extend(negative_samples)\n",
    "    data[\"label\"].extend([2]*len(negative_samples))\n",
    "    \n",
    "    return pd.DataFrame(data).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "enhanced_df = generate_enhanced_dataset()\n",
    "enhanced_df.to_csv(\"./Intention_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./intention_dataset.csv\")\n",
    "\n",
    "with open(\"./intention_fasttext.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df.iterrows():\n",
    "        label = f\"__label__{row['label']}\"\n",
    "        line = f\"{label} {row['text'].strip()}\\n\"\n",
    "        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始类别分布:\n",
      " label\n",
      "0    936\n",
      "1    728\n",
      "Name: count, dtype: int64\n",
      "\n",
      "验证集评估:\n",
      "(333, 0.9429429429429429, 0.9429429429429429)\n",
      "\n",
      "详细分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       187\n",
      "           1       1.00      0.87      0.93       146\n",
      "\n",
      "    accuracy                           0.94       333\n",
      "   macro avg       0.95      0.93      0.94       333\n",
      "weighted avg       0.95      0.94      0.94       333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fasttext\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 数据预处理\n",
    "def prepare_fasttext_data():\n",
    "    df = pd.read_csv(\"intention_dataset.csv\")\n",
    "    \n",
    "    # 统计类别分布\n",
    "    print(\"原始类别分布:\\n\", df.label.value_counts())\n",
    "    \n",
    "    # 转换格式\n",
    "    df['text'] = df['text'].str.replace(r'\\s+', ' ')  # 清理空格\n",
    "    df['fasttext_label'] = '__label__' + df['label'].astype(str)\n",
    "    \n",
    "    # 划分训练测试集\n",
    "    train, test = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "    \n",
    "    # 保存为FastText格式\n",
    "    train[['fasttext_label', 'text']].to_csv(\n",
    "        'intention_fasttext.train', \n",
    "        index=False, \n",
    "        sep=' ', \n",
    "        header=None,\n",
    "        quoting=3,  # 避免引号问题\n",
    "        escapechar=' '\n",
    "    )\n",
    "    \n",
    "    test[['fasttext_label', 'text']].to_csv(\n",
    "        'intention_fasttext.valid',\n",
    "        index=False,\n",
    "        sep=' ',\n",
    "        header=None,\n",
    "        quoting=3,\n",
    "        escapechar=' '\n",
    "    )\n",
    "\n",
    "prepare_fasttext_data()\n",
    "\n",
    "# 2. 模型训练（优化参数）\n",
    "model = fasttext.train_supervised(\n",
    "    input=\"intention_fasttext.train\",\n",
    "    epoch=200,         # 增加训练轮次\n",
    "    lr=0.1,            # 降低学习率\n",
    "    wordNgrams=3,      # 增加n-gram窗口\n",
    "    dim=200,           # 增加词向量维度\n",
    "    loss='ova',        # 更适合二分类\n",
    "    thread=4,          # 多线程加速\n",
    "    verbose=2        # 显示训练细节\n",
    ")\n",
    "\n",
    "# 3. 模型评估\n",
    "def evaluate_model():\n",
    "    # 在验证集上测试\n",
    "    print(\"\\n验证集评估:\")\n",
    "    print(model.test(\"intention_fasttext.valid\"))\n",
    "    \n",
    "    # 详细分类报告\n",
    "    y_true, y_pred = [], []\n",
    "    with open(\"intention_fasttext.valid\") as f:\n",
    "        for line in f:\n",
    "            true_label = int(line.split()[0].split('__')[-1])\n",
    "            text = ' '.join(line.strip().split()[1:])\n",
    "            pred_label = int(model.predict(text)[0][0].split('__')[-1])\n",
    "            \n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(pred_label)\n",
    "    \n",
    "    print(\"\\n详细分类报告:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_model()\n",
    "\n",
    "# 保存优化后的模型\n",
    "model.save_model(\"optimized_intent_model.ftz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：如何补办学生证？ 预测标签: 0, 置信度: 0.8596604466438293\n",
      "问题：文渊楼211的教室信息 预测标签: 0, 置信度: 0.8520693182945251\n",
      "问题：申请缓考的流程是什么？ 预测标签: 0, 置信度: 0.8602732419967651\n",
      "问题：C语言程序设计的上课地点在哪？ 预测标签: 0, 置信度: 0.8630637526512146\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model(\"intent_model.ftz\")\n",
    "\n",
    "def predict_intent(text):\n",
    "    label, prob = model.predict(text)\n",
    "    # 输出: label = ['__label__0'] or ['__label__1']\n",
    "    return int(label[0].replace(\"__label__\", \"\")), prob[0]\n",
    "\n",
    "# 示例\n",
    "test_questions = [\n",
    "    \"如何补办学生证？\",\n",
    "    \"文渊楼211的教室信息\",\n",
    "    \"申请缓考的流程是什么？\",\n",
    "    \"C语言程序设计的上课地点在哪？\"\n",
    "]\n",
    "for text in test_questions:\n",
    "    predicted_label, confidence = predict_intent(text)\n",
    "    print(f\"问题：{text} 预测标签: {predicted_label}, 置信度: {confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       186\n",
      "           1       1.00      0.93      0.96       147\n",
      "\n",
      "    accuracy                           0.97       333\n",
      "   macro avg       0.97      0.96      0.97       333\n",
      "weighted avg       0.97      0.97      0.97       333\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['intent_model_sklearn.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv(\"intention_dataset.csv\")\n",
    "\n",
    "# 划分训练集测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建模型管道\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 训练模型\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 测试模型\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(pipeline, \"intent_model_sklearn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：如何补办学生证？ 预测类别: 0, 置信度: 0.5570527163908637\n",
      "问题：文渊楼211的教室信息 预测类别: 0, 置信度: 0.5570527163908637\n",
      "问题：申请缓考的流程是什么？ 预测类别: 0, 置信度: 0.5570527163908637\n",
      "问题：C语言程序设计的上课地点在哪？ 预测类别: 0, 置信度: 0.5570527163908637\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"intent_model_sklearn.pkl\")\n",
    "\n",
    "def predict_intent(text):\n",
    "    pred = model.predict([text])[0]\n",
    "    prob = model.predict_proba([text]).max()\n",
    "    return int(pred), prob\n",
    "\n",
    "# 示例\n",
    "test_questions = [\n",
    "    \"如何补办学生证？\",\n",
    "    \"文渊楼211的教室信息\",\n",
    "    \"申请缓考的流程是什么？\",\n",
    "    \"C语言程序设计的上课地点在哪？\"\n",
    "]\n",
    "for text in test_questions:\n",
    "    predicted_label, confidence = predict_intent(text)\n",
    "    print(f\"问题：{text} 预测类别: {label}, 置信度: {confidence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "from typing import List, Tuple, Dict\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "\n",
    "# -------------------- 配置部分 --------------------\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"neo4j123456\"\n",
    "\n",
    "VECTOR_DB_PROCESSES = [\n",
    "    \"补办学生证流程\", \"缓考申请流程\", \"成绩单打印流程\",  # 完整列表参考你的流程数据\n",
    "    # ... 其他流程名称\n",
    "]\n",
    "\n",
    "# -------------------- 工具类 --------------------\n",
    "class Neo4jConnector:\n",
    "    def __init__(self):\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            NEO4J_URI,\n",
    "            auth=(NEO4J_USER, NEO4J_PASSWORD)\n",
    "        )\n",
    "        \n",
    "    def get_entities(self) -> List[str]:\n",
    "        \"\"\"获取所有实体名称\"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH (n) \n",
    "        WHERE n:Course OR n:Person OR n:Building OR n:Department\n",
    "        RETURN n.name as name\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            return [record[\"name\"] for record in result]\n",
    "\n",
    "class EntityRecognizer:\n",
    "    def __init__(self, entity_list: List[str]):\n",
    "        self.exact_entities = entity_list\n",
    "        self.fuzzy_index = self._build_fuzzy_index(entity_list)\n",
    "        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        \n",
    "    def _build_fuzzy_index(self, entities: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"构建语音哈希索引\"\"\"\n",
    "        index = {}\n",
    "        for entity in entities:\n",
    "            key = self._soundex(entity)\n",
    "            if key not in index:\n",
    "                index[key] = []\n",
    "            index[key].append(entity)\n",
    "        return index\n",
    "    \n",
    "    def _soundex(self, word: str) -> str:\n",
    "        \"\"\"中文语音编码简化版\"\"\"\n",
    "        first_char = word[0]\n",
    "        code = first_char\n",
    "        return code\n",
    "    \n",
    "    def exact_match(self, text: str) -> List[str]:\n",
    "        \"\"\"精确匹配实体\"\"\"\n",
    "        matched = []\n",
    "        for entity in self.exact_entities:\n",
    "            if entity in text:\n",
    "                matched.append(entity)\n",
    "        return matched\n",
    "    \n",
    "    def fuzzy_match(self, text: str, threshold: int = 2) -> List[str]:\n",
    "        \"\"\"模糊匹配实体\"\"\"\n",
    "        candidates = []\n",
    "        tokens = jieba.lcut(text)\n",
    "        for token in tokens:\n",
    "            if len(token) < 2:\n",
    "                continue\n",
    "            sound_key = self._soundex(token)\n",
    "            for entity in self.fuzzy_index.get(sound_key, []):\n",
    "                if levenshtein_distance(token, entity) <= threshold:\n",
    "                    candidates.append(entity)\n",
    "        return list(set(candidates))\n",
    "    \n",
    "    def semantic_match(self, text: str, top_k: int = 3) -> List[str]:\n",
    "        \"\"\"语义匹配实体\"\"\"\n",
    "        text_embed = self.model.encode(text)\n",
    "        entity_embeds = self.model.encode(self.exact_entities)\n",
    "        \n",
    "        similarities = np.dot(text_embed, entity_embeds.T)\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        return [self.exact_entities[i] for i in top_indices]\n",
    "\n",
    "class ProcessDetector:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        self.process_embeds = self.model.encode(VECTOR_DB_PROCESSES)\n",
    "        \n",
    "    def detect(self, query: str, threshold: float = 0.7) -> str:\n",
    "        \"\"\"检测流程类问题\"\"\"\n",
    "        query_embed = self.model.encode(query)\n",
    "        similarities = np.dot(query_embed, self.process_embeds.T)\n",
    "        max_idx = np.argmax(similarities)\n",
    "        \n",
    "        if similarities[max_idx] > threshold:\n",
    "            return VECTOR_DB_PROCESSES[max_idx]\n",
    "        return None\n",
    "\n",
    "# -------------------- 路由系统 --------------------\n",
    "class CampusAssistant:\n",
    "    def __init__(self):\n",
    "        # 初始化组件\n",
    "        self.neo4j = Neo4jConnector()\n",
    "        self.entity_recognizer = EntityRecognizer(self.neo4j.get_entities())\n",
    "        self.process_detector = ProcessDetector()\n",
    "        \n",
    "        # 缓存常用查询\n",
    "        self.cache = {}\n",
    "        \n",
    "    def _get_neo4j_answer(self, entities: List[str]) -> str:\n",
    "        \"\"\"执行Neo4j查询\"\"\"\n",
    "        # 示例查询逻辑，可根据实际需求扩展\n",
    "        query_template = \"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "        WHERE n.name IN $entities\n",
    "        RETURN n.name, type(r) as rel_type, m.name\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        with self.neo4j.driver.session() as session:\n",
    "            result = session.run(query_template, entities=entities)\n",
    "            return \"\\n\".join([f\"{record['n.name']} -> {record['rel_type']} -> {record['m.name']}\" \n",
    "                            for record in result])\n",
    "    \n",
    "    def _get_process_answer(self, process_name: str) -> str:\n",
    "        \"\"\"获取流程回答（模拟向量数据库查询）\"\"\"\n",
    "        # 此处应替换为实际的向量数据库查询\n",
    "        process_answers = {\n",
    "            \"补办学生证流程\": \"1. 登录教务系统...\\n2. 准备身份证复印件...\",\n",
    "            \"缓考申请流程\": \"1. 考前3天提交申请...\\n2. 院系审核...\",\n",
    "            # ... 其他流程的预定义回答\n",
    "        }\n",
    "        return process_answers.get(process_name, \"该流程的详细信息暂未收录\")\n",
    "    \n",
    "    def route_query(self, question: str) -> Tuple[str, str]:\n",
    "        \"\"\"路由查询并返回回答\"\"\"\n",
    "        # 第一步：检测流程类问题\n",
    "        process = self.process_detector.detect(question)\n",
    "        if process:\n",
    "            return (\"process\", self._get_process_answer(process))\n",
    "        \n",
    "        # 第二步：实体识别\n",
    "        entities = []\n",
    "        entities += self.entity_recognizer.exact_match(question)\n",
    "        if not entities:\n",
    "            entities += self.entity_recognizer.fuzzy_match(question)\n",
    "        if not entities:\n",
    "            entities += self.entity_recognizer.semantic_match(question)\n",
    "            \n",
    "        if entities:\n",
    "            return (\"neo4j\", self._get_neo4j_answer(entities))\n",
    "        \n",
    "        # 默认回答\n",
    "        return (\"general\", \"暂时无法回答这个问题，已记录您的需求\")\n",
    "\n",
    "# -------------------- 使用示例 --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = CampusAssistant()\n",
    "    \n",
    "    test_questions = [\n",
    "        \"如何补办学生证？\",\n",
    "        \"张老师的办公室在哪里？\",\n",
    "        \"计算机学院的课程安排是怎样的？\",\n",
    "        \"今天天气怎么样？\"\n",
    "    ]\n",
    "    \n",
    "    for q in test_questions:\n",
    "        q_type, answer = assistant.route_query(q)\n",
    "        print(f\"问题：{q}\")\n",
    "        print(f\"类型：{q_type}\")\n",
    "        print(f\"回答：{answer}\\n{'-'*40}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
