from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI


class RoutingAgent:
    def __init__(self, llm):
        self.llm = llm
        self.prompt = ChatPromptTemplate.from_template("""
        è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜åˆ¤æ–­æœ€åˆé€‚çš„å¤„ç†æ–¹å¼ï¼Œç±»åž‹åŒ…æ‹¬ï¼š
        - neo4jï¼šæ¶‰åŠæ•™å¸ˆã€è¯¾ç¨‹ã€æ•™å®¤ã€å­¦é™¢(ç½‘å€ç­‰)ã€å»ºç­‘ç­‰ç»“æž„åŒ–æ ¡å›­ä¿¡æ¯
        - vectorï¼šæ¶‰åŠå­¦ç”Ÿè¯è¡¥åŠžã€æˆç»©å•æ‰“å°ã€ç¼“è€ƒç”³è¯·ç­‰åŠžäº‹æµç¨‹ï¼ˆéžç»“æž„åŒ–ï¼‰
        - openï¼šé€šç”¨æ€§çŸ¥è¯†é—®ç­”ï¼Œä¸éœ€è¦ç½‘ç»œæœç´¢
        - search: éœ€è¦ç½‘ç»œæœç´¢çš„é—®é¢˜ï¼Œå¦‚å¤©æ°”æŸ¥è¯¢ç­‰

        âš ï¸ å¦‚æžœé—®é¢˜åŒ…å«å¤šä¸ªå­é—®é¢˜ï¼Œè¯·æ‹†åˆ†ï¼Œæ¯ä¸ªå­é—®é¢˜å½’ç±»ä¸€ä¸ªç±»åž‹ã€‚

        ðŸ“Œ è¿”å›žæ ¼å¼å¦‚ä¸‹ï¼ˆ**æ ‡å‡† JSON**ï¼‰ï¼š
        {{
        "question": ["å­é—®é¢˜1", "å­é—®é¢˜2", ...],
        "type": ["neo4j", "vector", ...]
        }}

        ç¤ºä¾‹ï¼š

        ç”¨æˆ·ï¼šä»‹ç»ä¸€ä¸‹çŽ‹æ´¥è€å¸ˆï¼Ÿ
        å›žç­”ï¼š
        ```json
        {{
        "question": ["ä»‹ç»ä¸€ä¸‹çŽ‹æ´¥è€å¸ˆï¼Ÿ"],
        "type": ["neo4j"]
        }}```
        ç”¨æˆ·ï¼šè®¡ç®—æœºç½‘ç»œå®žè·µçš„æ•™å­¦ç­æœ‰å¤šå°‘äººï¼Ÿå­¦ç”Ÿç”³è¯·è¯¾ç¨‹å…ä¿®åŠžç†æµç¨‹çš„å…·ä½“æ­¥éª¤æœ‰å“ªäº›ï¼Ÿä»‹ç»ä¸€ä¸‹å›¾çµæµ‹è¯•ã€‚
        å›žç­”ï¼š
        ```json
        {{
        "question": ["è®¡ç®—æœºç½‘ç»œå®žè·µçš„æ•™å­¦ç­æœ‰å¤šå°‘äººï¼Ÿ", "å­¦ç”Ÿç”³è¯·è¯¾ç¨‹å…ä¿®åŠžç†æµç¨‹çš„å…·ä½“æ­¥éª¤æœ‰å“ªäº›ï¼Ÿ", "ä»‹ç»ä¸€ä¸‹å›¾çµæµ‹è¯•ã€‚"],
        "type": ["neo4j", "vector", "open"]
        }}``` 
        å½“å‰é—®é¢˜ï¼š{question}""")

        self.chain = self.prompt | self.llm | self._parse_output

    def _parse_output(self, response):
        return response.content.strip()

    async def route(self, question: str) -> str:
        return await self.chain.ainvoke({"question": question})